% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knn_sleepwalk_functions.R
\name{KnnSleepwalk}
\alias{KnnSleepwalk}
\title{K-nearest neighbors Sleepwalk}
\usage{
KnnSleepwalk(
  embedding,
  orig_data,
  k = 100,
  ranks = FALSE,
  rann = FALSE,
  output_file = NULL,
  point_size = 1.5,
  plot_names = c("KNN embedding space", "KNN high-dim space"),
  kfn = FALSE,
  metric = "euclidean",
  ...
)
}
\arguments{
\item{embedding}{The 2-D embedding of the data matrix, in matrix format with
data points as rows and two columns.}

\item{orig_data}{A data matrix with data points as rows and features as columns.
the matrix must already be filtered by the markers you care about.}

\item{k}{The number of the nearest neighbors to be visualized}

\item{ranks}{Whether to visualize neighbor ranks using a color gradient}

\item{rann}{Whether to use faster neighbor search (only for nearest neighbors
and not used with cosine/manhattan distances)}

\item{output_file}{The file to save your sleepwalk html page to}

\item{point_size}{How big you want the point on the plots to be}

\item{plot_names}{What you want the comparison plots to be named. This vector
of strings needs to match the number of plots (eg. 2 if we're dealing with
the default of 2 plots here).}

\item{kfn}{Whether you want to look at the k-farthest neighbors. If false
(default) then you look at the K-nearest neighbors.}

\item{metric}{The distance metric you're going to use for the neighbor
finding computation for the original high-dimensional data. For the embedding,
Euclidean is used. Default is also set to euclidean, with manhattan and cosine
as other options.}

\item{...}{Any other keyword arguments to pass onto \code{RANN::nn2} if used}
}
\description{
Takes a data matrix and a 2-D embedding as input. It produces
a 'KNN matrix' and places that along with the aforementioned inputs into the
sleepwalk function. Unlike the default KNN sleepwalk function, this one makes
two KNN matrices, like UMAP space vs high-D space for comparisons across the
same embedding.
}
